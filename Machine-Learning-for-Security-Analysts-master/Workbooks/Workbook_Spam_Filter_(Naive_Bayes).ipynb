{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workbook: Spam Filter (Naive Bayes).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3m6fCeVmaUX",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning for Security Analysts - Workbook </br> Spam Filter (Naive Bayes)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Author: GTKlondike\n",
        "</br>\n",
        "Email: GTKlondike@gmail.com\n",
        "</br>\n",
        "YouTube: [NetSec Explained](https://www.youtube.com/channel/UCsKK7UIiYqvK35aWrCCgUUA)\n",
        "\n",
        "**Dataset:** https://github.com/NetsecExplained/Machine-Learning-for-Security-Analysts\n",
        "\n",
        "**Goal:** This workbook will walk you through the steps to build, train, test, and evaluate a Naive Bayes spam classifier from the ground up\n",
        "\n",
        "**Outline:** \n",
        "* Initial Setup\n",
        "* Tokenization\n",
        "* Load Training Data\n",
        "* Create Predict Function\n",
        "* Test and Evaluate Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gadApB28w-AQ",
        "colab_type": "text"
      },
      "source": [
        "## Instructions\n",
        "To use Jupyter notebooks:\n",
        "* To run a cell, click on the play button to the left of the code or pressh shift+enter\n",
        "* You will see a busy indicator in the top left area while the runtime is executing\n",
        "* A number will appear when the cell is done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daGfIEJq0pvr",
        "colab_type": "text"
      },
      "source": [
        "# Initial Setup\n",
        "We'll start by downloading the data and loading the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-prBWrmKhi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data from Github\n",
        "! git clone https://github.com/NetsecExplained/Machine-Learning-for-Security-Analysts.git\n",
        "  \n",
        "# Install dependencies\n",
        "! pip install nltk sklearn pandas matplotlib seaborn\n",
        "data_dir = \"Machine-Learning-for-Security-Analysts\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az-RDxD-JqXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Common imports\n",
        "import re, os, math, string, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Import Seaborn heatmap graphs\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Import Natural Language ToolKit library and download dictionaries\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(\"\\n### Libraries Imported ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0G5Qct1JuGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test email from lecture slides\n",
        "test_email = \"\"\"\n",
        "Re: Re: East Asian fonts in Lenny. Thanks for your support.  Installing unifonts did it well for me. ;)\n",
        "Nima\n",
        "--\n",
        "To UNSUBSCRIBE, email to debian-user-REQUEST@lists.debian.org\n",
        "with a subject of \"unsubscribe\". Trouble? Contact listmaster@lists.debian.org\n",
        "\"\"\"\n",
        "print(test_email)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfTFdFM0sR6",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "Continuing from where we left off with the slides, we'll start by creating our tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brp3CPvjJwgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define tokenizer\n",
        "#   The purpose of a tokenizer is to separate the features from the raw data\n",
        "\n",
        "def tokenizer(text):\n",
        "  \"\"\"Separates feature words from the raw data\n",
        "  Keyword arguments:\n",
        "    text ---- The full email body\n",
        "    \n",
        "  :Returns -- The tokenized words; returned as a list\n",
        "  \"\"\"\n",
        "  \n",
        "  # Retrieve a list of punctuation characters, a list of stopwords, and a stemmer function\n",
        "  punctuations = list(string.punctuation)\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "  stemmer = nltk.stem.PorterStemmer()\n",
        "  \n",
        "  \n",
        "  # Set email body to lowercase, separate words and strip out punctuation\n",
        "  tokens = nltk.word_tokenize(text.lower())\n",
        "  tokens = [i.strip(''.join(punctuations)) \n",
        "            for i in tokens \n",
        "            if i not in punctuations]\n",
        "  \n",
        "  \n",
        "  # User Porter Stemmer on each token\n",
        "  tokens = [stemmer.stem(i)\n",
        "            for i in tokens]\n",
        "  return [w for w in tokens if w not in stopwords and w != \"\"]\n",
        "\n",
        "\n",
        "print(\"\\n### Tokenizer defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mthd1gD1u9XH",
        "colab_type": "text"
      },
      "source": [
        "## Task 1 - Tokenize an email\n",
        "1. Print the full email, **test_email**\n",
        "2. Print the results of **tokenizer(test_email)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGux71ElzpPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see how our tokenizer changes our email\n",
        "print(\"\\n- Test Email Body -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize test email\n",
        "print(\"\\n - Tokenized Output -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_7JHrVRvN8W",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 - Define readEmail() function\n",
        "1. Given an email as input, use the **tokenizer()** function to get a list of words\n",
        "2. Manually collect the word count of each word, and save the results in a *dict()* table\n",
        "  - Ex: {'earth':2, 'water':9, 'fire':2, 'air':1}\n",
        "3. Collect the total word count of the email, and save the results as an *int()*\n",
        "4. Return the *dictionary* table and the word count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSdZEog9gZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define email reader\n",
        " \n",
        "def readEmail(email):\n",
        "  \"\"\"Reads an email and returns word counts\n",
        "  Keyword arguments:\n",
        "    email --- The email body to be read\n",
        "\n",
        "  :Returns -- The count of each word; returned as a dict\n",
        "           -- The total number of words; returned as a int\n",
        "  \"\"\"\n",
        "  \n",
        "  # Retrieve list of tokens\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  # Build table\n",
        "  # (Write code here)\n",
        "\n",
        "  \n",
        "  \n",
        "    \n",
        "  # Get word count\n",
        "  # (Write code here)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  # (Keep the following lines)\n",
        "  return table, word_count\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Email Reader Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crDXpgSvKMcF",
        "colab_type": "text"
      },
      "source": [
        "## Task 2a (optional) - Read the test_email\n",
        "1. Collect the results of **readEmail(test_email)**\n",
        "2. Print the word counts of each word token\n",
        "3. Print the count of total words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmOWI7Bj1wVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see how readEmail interprets our test email\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n- Word Counts -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n- Total Words in Email -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUJ5yVhM1Ua-",
        "colab_type": "text"
      },
      "source": [
        "# Load Training Data\n",
        "With our tokenizer defined, let's take a look at our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0qgnw0j1G93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5 things to keep track of:\n",
        "\n",
        "#   1. The NUMBER of unique words\n",
        "#     This will be calculated as everything is loaded\n",
        "\n",
        "unique_words_table = set()\n",
        "\n",
        "\n",
        "#   2. The TOTAL NUMBER of words in Spam\n",
        "#   3. The TOTAL NUMBER of words in Ham\n",
        "\n",
        "spam_table_len = 0\n",
        "ham_table_len = 0\n",
        "\n",
        "\n",
        "#   4. The COUNT of each word in Spam\n",
        "#   5. the COUNT of each word in Ham\n",
        "\n",
        "spam_table = dict()\n",
        "ham_table = dict()\n",
        "\n",
        "\n",
        "print(\"\\n### Initialized Feature Tables ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uXA7P3vptp6",
        "colab_type": "text"
      },
      "source": [
        "## Task 3a - Define learnHam() function\n",
        "1. Collect the results of a provided email using the **readEmail()** function\n",
        "2. Update the **unique_words_table** with new word tokens found in the email\n",
        "3. Add the email word counts to the **ham_table_len** counter\n",
        "4. Add word tokens and their word counts to the **ham_table**\n",
        "\n",
        "\\* This function should be semi-identical to the *learnSpam()* function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3zN19mcKCtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Ham learning\n",
        "\n",
        "def learnHam(email):\n",
        "  \"\"\"Reads an email, updates Ham table and word counts\n",
        "  Keyword arguments:\n",
        "    email --- The email body to be read\n",
        "\n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Include global variables\n",
        "  global ham_table\n",
        "  global ham_table_len\n",
        "  global unique_words_table\n",
        "\n",
        "  # Read the email\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  # Add UNIQUE words\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  # Add word count to TOTAL number of Ham words\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  # Add word tokens to Ham table\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "\n",
        "    \n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Ham Learner Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1DjO6a9qsoD",
        "colab_type": "text"
      },
      "source": [
        "## Task 3b - Define learnSpam() function\n",
        "1. Collect the results of a provided email using the **readEmail()** function\n",
        "2. Update the **unique_words_table** with new word tokens found in the email\n",
        "3. Add the email word counts to the **spam_table_len** counter\n",
        "4. Add word tokens and their word counts to the **spam_table**\n",
        "\n",
        "\\* This function should be semi-identical to the *learnSpam()* function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlwIwiEUKCBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Spam learning\n",
        "\n",
        "def learnSpam(email):\n",
        "  \"\"\"Reads an email, updates Spam table and word counts\n",
        "  Keyword arguments:\n",
        "    email --- The email body to be read\n",
        "\n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Include global variables\n",
        "  global spam_table\n",
        "  global spam_table_len\n",
        "  global unique_words_table\n",
        "\n",
        "  # Read the email\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  # Add UNIQUE words\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  # Add word count to TOTAL number of Spam words\n",
        "  # (Write code here)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  # Add word tokens to Spam table\n",
        "  # (Write code here)\n",
        "  \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "# (Keep the following lines)    \n",
        "print(\"\\n### Spam Learner Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwSoU0GznayJ",
        "colab_type": "text"
      },
      "source": [
        "## Task 4 - Load training data\n",
        "1. Initialize two *int()* counters, named **spam_count** and **ham_count**, set to **0**\n",
        "2. Load the email bodies from the **/ham** directory using the **learnHam()** function\n",
        "  - Increment the *ham_count* counter for each email read\n",
        "3. Load the email bodies form the **/spam** directory using the **learnSpam()** function\n",
        "  - Increment the *spam_count* counter for each email read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syIESbQWKFWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the training data\n",
        "\n",
        "# Store count for calculating priors\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load all of the emails from the \"ham\" directory\n",
        "print(\"- Training Ham -\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# Load all of the emails from the \"spam\" directory\n",
        "print(\"- Training Spam -\")\n",
        "# (Write code here)\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Training complete ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spLxmXnnon05",
        "colab_type": "text"
      },
      "source": [
        "## Task 4a (Optional) - View training data\n",
        "1. Show the word counts and values of the first 5 words in the **ham_table**\n",
        "2. Show the word counts and values of the first 5 words in the **spam_table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9gLllQtKJjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see how our spam_table looks\n",
        "\n",
        "\n",
        "print(\"- Showing ham_table Elements -\")\n",
        "#(Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"- Showing spam_table Elements -\")\n",
        "#(Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX1psGyU1ttI",
        "colab_type": "text"
      },
      "source": [
        "# Create Predict Function\n",
        "Now that the training data has been loaded, let's create a repeatable function that can perform predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY8YM0zjt-ZM",
        "colab_type": "text"
      },
      "source": [
        "## The mathy bits\n",
        "### Multinomial Naive Bayes function\n",
        "$P(Spam|email) = \\dfrac{P(email|Spam) \\cdot P(Spam)}{P(email)}\\\\$\n",
        "$P(word|Spam) = \\dfrac{Count(word,Spam) + \\alpha}{Count(Spam) + \\alpha \\cdot Count(unique\\ words)}\\\\$\n",
        "$P(Spam) = \\dfrac{spam\\ count}{spam\\ count + ham\\ count}\\\\$\n",
        "\n",
        "### Properties of logarithms \n",
        "#### Multiplication\n",
        "\n",
        "$log(A \\cdot B) = log(A) + log(B)\\\\$\n",
        "\n",
        "\n",
        "#### Division\n",
        "\n",
        "$log(\\dfrac{A}{B}) = log(A) - log(B)\\\\$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Warem4MYKME6",
        "colab_type": "code",
        "outputId": "bdcae06b-703e-410f-c8b2-39be875fbd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Define the predict function\n",
        "\n",
        "def predict(email, alpha=1, print_probs=False):\n",
        "  \"\"\"Reads an email, updates Ham table and word counts\n",
        "  Keyword arguments:\n",
        "    email -------- The email body to be read\n",
        "    alpha -------- Smoothing alpha to be applied (almost always 1)\n",
        "    print_probs -- Print probabilities for debugging purposes\n",
        "\n",
        "  :Returns ------- The predicted class label; as a str\n",
        "  \"\"\"\n",
        "  \n",
        "  # Read the email\n",
        "  tokens = tokenizer(email)\n",
        "\n",
        "  # Retrieve N from (1. The NUMBER of unique words)\n",
        "  N = len(unique_words_table)\n",
        "  \n",
        "  # Calculate priors - P(spam) and P(ham)\n",
        "  spam_prior = spam_count / (spam_count + ham_count)\n",
        "  ham_prior  =  ham_count / (spam_count + ham_count)\n",
        "  \n",
        "  # Retrieve denominator values for Spam and Ham calculations\n",
        "  spam_denominator = spam_table_len + N*alpha\n",
        "  ham_denominator = ham_table_len + N*alpha\n",
        "  \n",
        "  \n",
        "  \n",
        "  # Calculate the numerators\n",
        "  spam_numerator = 1\n",
        "  ham_numerator = 1\n",
        "  \n",
        "  for word in tokens:\n",
        "    \n",
        "    # Set to 0 incase word doesn't exist\n",
        "    spam_table.setdefault(word, 0)\n",
        "    ham_table.setdefault(word, 0)\n",
        "    \n",
        "    spam_numerator *= spam_table[word] + alpha\n",
        "    ham_numerator *=  ham_table[word] + alpha\n",
        "  \n",
        "  \n",
        "  \n",
        "  # Calculate the probabilities\n",
        "  #   Using log properties to prevent overflows/underflows  \n",
        "  spam_probability = math.log(spam_prior) + (math.log(spam_numerator) - math.log(spam_denominator ** len(tokens)))\n",
        "  ham_probability  = math.log(ham_prior) + (math.log( ham_numerator) - math.log( ham_denominator ** len(tokens)))\n",
        "\n",
        "  \n",
        "  \n",
        "  # Print probabilities for debugging purposes\n",
        "  if print_probs == True:\n",
        "    print(\"- Probabilities -\")\n",
        "    print(\"Spam Probability: {}\".format(spam_probability))\n",
        "    print(\"Ham Probability:  {}\".format(ham_probability))\n",
        "  \n",
        "  \n",
        "  # Make classification decision\n",
        "  if (spam_probability > ham_probability):\n",
        "    return \"spam\"\n",
        "  else:\n",
        "    return \"ham\"\n",
        "  \n",
        "\n",
        "print(\"\\n### Prediction Function Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "### Prediction Function Defined ###\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qok7wOn4maJD",
        "colab_type": "text"
      },
      "source": [
        "## Task 5 - Predict test_email\n",
        "1. Execute the **predict()** function on **test_email**\n",
        "  - Set **print_probs=True** to display probability calculations\n",
        "2. Print the predicted class\n",
        "3. Print *test_email*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FnuImTKax5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict our test email\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n- Predicted Class -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n- Email Body -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgqG_zBs2LHg",
        "colab_type": "text"
      },
      "source": [
        "# Test and Evaluate the Model\n",
        "OK, we have our training data loaded and a function to perform predictions. Now it's time to test and evaluate our model\n",
        "\n",
        "But first, we're going to define a helper function to display our evaluation reports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM58ZpFsecIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define report generator\n",
        "\n",
        "def generate_report(cmatrix, score):\n",
        "  \"\"\"Generates and displays graphical reports\n",
        "  Keyword arguments:\n",
        "    cmatrix - Confusion matrix generated by the model\n",
        "    score --- Score generated by the model\n",
        "    \n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Generate confusion matrix heatmap\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cmatrix, \n",
        "              annot=True, \n",
        "              fmt=\"d\", \n",
        "              linewidths=.5, \n",
        "              square = True, \n",
        "              cmap = 'Blues', \n",
        "              annot_kws={\"size\": 16}, \n",
        "              xticklabels=['ham', 'spam'], \n",
        "              yticklabels=['ham', 'spam'])\n",
        "\n",
        "  plt.xticks(rotation='horizontal', fontsize=16)\n",
        "  plt.yticks(rotation='horizontal', fontsize=16)\n",
        "  plt.xlabel('Actual Label', size=20);\n",
        "  plt.ylabel('Predicted Label', size=20);\n",
        "\n",
        "  title = 'Accuracy Score: {0:.4f}'.format(score)\n",
        "  plt.title(title, size = 20);\n",
        "\n",
        "  # Display confusion matrix\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "print(\"\\n### Report Generator Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6HsNF9eKNmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to test the model\n",
        "\n",
        "def testModel(alpha=1):\n",
        "  \"\"\"Evaluates the model with the given alpha\n",
        "  Keyword arguments:\n",
        "    alpha --- Smoothing alpha to be applied (almost always 1)\n",
        "\n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Initialize confusion matrix (true label vs predicted label)\n",
        "  spam_spam = 0\n",
        "  spam_ham  = 0\n",
        "  ham_ham   = 0\n",
        "  ham_spam  = 0\n",
        "  \n",
        "  \n",
        "  # Predict testing emails\n",
        "  print(\"- Predicting Testing Emails -\")\n",
        "  for filename in os.listdir(data_dir + '/test'):\n",
        "      with open(data_dir + \"/test/\" + filename, 'r') as f:\n",
        "          prediction = predict(f.read())\n",
        "          true_label = re.split(\"txt\\.\", filename)[1]\n",
        "          \n",
        "          # Craft confusion matrix counts\n",
        "          if (true_label == 'ham'):\n",
        "            if (prediction == 'ham'):\n",
        "              ham_ham += 1\n",
        "            else:\n",
        "              ham_spam += 1\n",
        "          elif (true_label == 'spam'):\n",
        "            if (prediction == 'spam'):\n",
        "              spam_spam += 1\n",
        "            else:\n",
        "              spam_ham += 1\n",
        "              \n",
        "              \n",
        "  # Calculate statistics\n",
        "  cmatrix = [[ham_ham, spam_ham], \n",
        "             [ham_spam, spam_spam]]\n",
        "  correctly_classified = ham_ham + spam_spam\n",
        "  total_predictions   = ham_ham + spam_spam + ham_spam + spam_ham\n",
        "  accuracy = float(correctly_classified) / total_predictions\n",
        "\n",
        "  \n",
        "  # Print testing statistics\n",
        "  print(\"\\n- Printing Test Statistics -\\n\")\n",
        "  print(\"Total Emails: \", total_predictions)\n",
        "  print(\"Correctly classified: \", correctly_classified)\n",
        "  generate_report(cmatrix, accuracy)\n",
        "  \n",
        "  \n",
        "print(\"\\n### Model Evaluator Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCCTh3PiKPDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testModel()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}